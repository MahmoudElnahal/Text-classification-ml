{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07511fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arega\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.4.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\arega\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 1.4.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arega\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template, jsonify\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def load_model(filename):\n",
    "    try:\n",
    "        # Load the model from the file\n",
    "        loaded_model = pickle.load(open(filename, \"rb\"))\n",
    "        return loaded_model\n",
    "    except:\n",
    "        print(\"Error loading the model\")\n",
    "        return None\n",
    "    \n",
    "# Initialize the PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "# Get Arabic stopwords\n",
    "sw = stopwords.words('arabic')\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text)\n",
    "    text = re.sub('[^ุก-ู0-9 ]+', '', text).strip()  ## arabic\n",
    "    filtered_words = []\n",
    "    for word in text.lower().split():   ## arabic \n",
    "        if word not in sw:\n",
    "            filtered_words.append(ps.stem(word))\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def predict_label_from_user_input(clf, tfidf_vectorizer, user_input):\n",
    "    cleaned_text = clean(user_input)  # You need to define your clean() function\n",
    "    # Transform the cleaned text using the fitted vectorizer\n",
    "    cleaned_text = count_vect.transform([cleaned_text])\n",
    "    text_vectorized = tfidf_vectorizer.transform(cleaned_text)\n",
    "    \n",
    "    # Predict using the trained classifier\n",
    "    predicted_label = clf.predict(text_vectorized)\n",
    "    \n",
    "    return predicted_label[0]\n",
    "\n",
    "# Function to predict class\n",
    "def predict_text(user_input):\n",
    "    global model, tfidf_vectorizer\n",
    "    predicted = predict_label_from_user_input(model, tfidf_vectorizer, user_input)\n",
    "    return predicted\n",
    "\n",
    "# Flask route\n",
    "@app.route('/predict', methods=['POST','GET'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    text = data['text']\n",
    "    predicted = predict_text(text)\n",
    "    return jsonify({'predicted': predicted})\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def upload_file():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file']\n",
    "        if file:\n",
    "            text = file.read().decode('utf-8')\n",
    "            predicted_label = predict_label_from_text(clf, tfidf_vectorizer, text)\n",
    "            return render_template('result.html', text=text, predicted_label=predicted_label)\n",
    "    return render_template('upload.html')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load models\n",
    "    model_filename = 'clf.sav'\n",
    "    tfidf_filename = 'tfidf_transformer.sav'\n",
    "    count_vect_filename = 'count_vect.sav'\n",
    "    model = load_model(model_filename)\n",
    "    tfidf_vectorizer = load_model(tfidf_filename)\n",
    "    count_vect = load_model(count_vect_filename)\n",
    "    \n",
    "    # Run Flask app\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d996e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
